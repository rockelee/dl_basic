{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import skimage\n",
    "import skimage.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2' \n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "s = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.framework.ops.Graph at 0x7f6f9205f050>,\n",
       " <tensorflow.python.framework.ops.Graph at 0x7f6f9205f050>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.graph, tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./juri1.jpg\"\n",
    "juri = tf.image.decode_image(tf.read_file(path), channels=3, name=\"decode_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = s.run(juri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "juri1 = juri - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [juri, juri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e04973e0ea18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "a[0][:,:,1] = a[0][:,:,1] - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about string\n",
    "a = tf.constant(dtype=tf.string, value=\"a,b,c\", shape=[])\n",
    "b = tf.constant(dtype=tf.string, value=\"d,e,f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a,b,c/d,e,f', 'a,b,cd,e,f')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.run(tf.string_join([a,b], separator='/')) ,\\\n",
    "s.run(tf.reduce_join([a,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# about variable assign_add\n",
    "v = tf.Variable(0, trainable=False)\n",
    "v_add = v.assign_add(1)\n",
    "v.initializer.run()\n",
    "for i in range(16):\n",
    "    print(s.run(v_add))\n",
    "    print s.run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "1 0.09895193\n",
      "2 0.09791484\n",
      "3 0.09688862\n",
      "4 0.095873155\n",
      "5 0.094868325\n",
      "6 0.09387404\n",
      "7 0.092890166\n",
      "8 0.09191661\n",
      "9 0.09095325\n",
      "10 0.089999996\n"
     ]
    }
   ],
   "source": [
    "# about decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "initial_learning_rate = 0.1 #初始学习率\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate,\n",
    "                                           global_step=global_step,\n",
    "                                           decay_steps=10,decay_rate=0.9, staircase=False)\n",
    "# opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "add_global = global_step.assign_add(1)\n",
    "s.run(tf.global_variables_initializer())\n",
    "print(s.run(learning_rate))\n",
    "for i in range(10):\n",
    "    add_g, rate = s.run([add_global, learning_rate])\n",
    "    print add_g, rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09000000000000001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 * pow(0.9, 10/10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myprob(score):\n",
    "    return 1./(1+np.exp(-score))\n",
    "\n",
    "def myce(x, z):\n",
    "    return z * -np.log( myprob(x) ) + (1-z) * -np.log(1-myprob(x))\n",
    "\n",
    "def myce1(x, z):\n",
    "    return np.max(x,0) - x*z + np.log(1+np.exp(-np.abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = tf.constant([2,3,4], dtype=tf.float32)\n",
    "label = tf.constant([1,2,0], dtype=tf.float32)\n",
    "ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=prob, labels=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.126928 , -2.9514127,  4.01815  ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myprob(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "z = 1\n",
    "myce1(x,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6931471805599453, 0.6931471805599453)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "myce(x, 1), myce1(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-1)*np.log(1-myprob(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.array([1.0, 2.0, 3.0, 4.0, 5.0]))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "one_element = iterator.get_next()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    for i in range(5):\n",
    "        print(sess.run(one_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootpath = tf.constant(\"/home/llhan/workspace/learn_dl/bs/dataset2014_bak/dataset/\", dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0.048719, 0.123286, 0.048719,\n",
    "0.123286, 0.311981, 0.123286,\n",
    "0.048719, 0.123286, 0.048719]).reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(dtype=tf.float32, shape=[5,5,1])\n",
    "b = tf.placeholder(dtype=tf.float32, shape=[3,3,1,1])\n",
    "tf.nn.conv2d(a,b, strides=[1,1,1,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussian_kernel = tf.constant(np.array([0.048719, 0.123286, 0.048719,\n",
    "0.123286, 0.311981, 0.123286,\n",
    "0.048719, 0.123286, 0.048719]).reshape(3,3,1,1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = gaussian_kernel[0::2,0::2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip((1,2,3),(4,5,6),(7,8,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse(filenames):\n",
    "    \n",
    "    print filenames.shape, filenames.dtype\n",
    "    relpaths = tf.decode_csv(filenames, [[\"\"],[\"\"],[\"\"],[\"\"]])\n",
    "#     print relpaths.shape, relpaths.dtype\n",
    "    print type(relpaths), len(relpaths), relpaths[0].shape, relpaths[0].dtype\n",
    "#     return relpaths\n",
    "    \n",
    "    fullpaths = [tf.reduce_join([rootpath, i]) for i in relpaths]\n",
    "    img_strings = [tf.read_file(i) for i in fullpaths]\n",
    "    img_decode = [tf.image.decode_image(i) for i in img_strings]  #prev, curr, bkg is [natch, height, width, 3], gt is [batch, hegith, width, 1]\n",
    "#     return img_decode\n",
    "    gt = img_decode[-1]\n",
    "    img_decode = img_decode[:-1]\n",
    "    \n",
    "    scale0 = [tf.cast(tf.image.rgb_to_grayscale(i), tf.float32) for i in img_decode]  # rgb2gray， channels is 1, shape=[?,?,1]\n",
    "    scale1 = [tf.nn.conv2d(i, gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\") for i in scale0] # if using dataset.batch, shape=[batch_size,?,?,1]\n",
    "#     scale1 = [i[0::2, 0::2, :, :] for i in scale1]\n",
    "#     scale2 = [tf.nn.conv2d(i, gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\") for i in scale1]\n",
    "#     scale2 = [i[0::2, 0::2, :, :] for i in scale2]\n",
    "#     scale0 = tf.concat(scale0, axis=2)\n",
    "#     scale1 = tf.concat(scale1, axis=2)\n",
    "#     scale2 = tf.concat(scale2, axis=2)\n",
    "    \n",
    "#     gt = gt[:,:,0]\n",
    "#     gt = tf.\n",
    "    \n",
    "    return scale1 + [gt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as s:\n",
    "    print(s.run(tf.stack([rootpath]*5, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(value=[\"c,b,a\", \"c,b,a\"], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.constant(value=[[\"a,b,c\"],[\"c,b,a\"]], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    a = sess.run(tf.decode_csv([\"a,b,c\", \"c,b,a\"], [[\"\"],[\"\"],[\"\"]]))\n",
    "    b = sess.run(tf.decode_csv([[\"a,b,c\"],[\"c,b,a\"]], [[\"\"],[\"\"],[\"\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2], b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    a = sess.run(tf.reduce_join([[\"a\",\"b\"],[\"c\",\"d\"]],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(dtype=tf.float32, shape=[3,None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.unstack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([\"/home/llhan/workspace/learn_dl/bs/dataset2014_bak/dataset/baseline/highway/input/in000570.jpg\", \n",
    "                 \"/home/llhan/workspace/learn_dl/bs/dataset2014_bak/dataset/baseline/highway/groundtruth/gt000570.png\"], dtype=tf.string)\n",
    "tf.read_file(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(dtype=tf.float32, shape=[2,3])\n",
    "b = tf.reshape(a, [-1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse3(filenames):\n",
    "    relpaths = tf.decode_csv(filenames, [[\"\"],[\"\"],[\"\"],[\"\"]])  # a list of 1-D tensor, each element is a batch of prevs, or currs, or bkgs, or gts.\n",
    "    print relpaths[0].dtype, relpaths[0].shape\n",
    "#     return relpaths\n",
    "    \n",
    "    prev_path = tf.reduce_join([rootpath, relpaths[0]])\n",
    "    print prev_path.shape\n",
    "    prev_img = tf.reshape(tf.cast(tf.image.rgb_to_grayscale(tf.image.decode_image(tf.read_file(prev_path))), dtype=tf.float32), shape=[-1, 240, 320, 1])\n",
    "    print prev_img.shape\n",
    "    \n",
    "    prev_img_downscale1 = tf.nn.conv2d(prev_img,  gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\")[:,0::2,0::2,:]\n",
    "    print prev_img_downscale1\n",
    "    \n",
    "    prev_img_downscale2 = tf.nn.conv2d(prev_img_downscale1, gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\")[:,0::2,0::2,:]\n",
    "    print prev_img_downscale2\n",
    "    \n",
    "    prev_img = tf.reshape(prev_img, shape=[240, 320, 1])\n",
    "    prev_img_downscale1 = tf.reshape(prev_img_downscale1, shape=[120, 160, 1])\n",
    "    prev_img_downscale2 = tf.reshape(prev_img_downscale2, shape=[60, 80, 1])\n",
    "    \n",
    "    \n",
    "    return prev_img_downscale2\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "# rootpath1 = tf.stack([rootpath]*batch_size, axis=0)\n",
    "\n",
    "csv = tf.data.TextLineDataset(\"./bs/mybs/train.csv\")\n",
    "csv = csv.map(_parse3)\n",
    "csv = csv.shuffle(buffer_size=1000)   # 先 shuffle 后 map， 最后 batch。 还是先 map, 然后shuffle，最后batch\n",
    "csv = csv.batch(batch_size)\n",
    "\n",
    "iterator_csv = csv.make_one_shot_iterator()\n",
    "one_element_csv = iterator_csv.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_element_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    a = sess.run(one_element_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _parse2(filenames):\n",
    "    def get_pyramid(relpaths):\n",
    "        fullpaths = tf.reduce_join([rootpath1, relpaths], axis=0)\n",
    "        imgs = [tf.cast(tf.image.rgb_to_grayscale(tf.image.decode_image(tf.read_file(fullpaths[i]))), dtype=tf.float32)  \\\n",
    "                for i in range(fullpaths.shape.as_list()[0])]\n",
    "        imgs_downscale1 = tf.nn.conv2d(imgs, gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\")[:,0::2,0::2,:]\n",
    "        imgs_downscale2 = tf.nn.conv2d(imgs_downscale1, gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\")[:,0::2,0::2,:]\n",
    "        return imgs, imgs_downscale1, imgs_downscale2\n",
    "    \n",
    "    def get_gt_and_mask(relpaths):\n",
    "        gt_paths = tf.reduce_join([rootpath1, relpaths], axis=0)    #1. 读取并解码，转换为2-Dtensor，转换为二值图, 转换为float类型\n",
    "\n",
    "        raw_gt_imgs = [tf.image.decode_image(tf.read_file(gt_paths[i])) for i in range(gt_paths.shape.as_list()[0])]\n",
    "        gt_imgs = [tf.cast(tf.greater_equal(i, 170), dtype=tf.float32) for i in raw_gt_imgs]\n",
    "        gt_imgs = tf.stack(gt_imgs, axis=0)\n",
    "        gt_imgs = tf.squeeze(gt_imgs)\n",
    "\n",
    "        mask_imgs = [tf.cast(tf.not_equal(i, 85), dtype=tf.float32) for i in raw_gt_imgs]\n",
    "        mask_imgs = tf.stack(mask_imgs, axis=0)\n",
    "        mask_imgs = tf.squeeze(mask_imgs)\n",
    "        return gt_imgs, mask_imgs\n",
    "\n",
    "    print type(filenames), filenames.shape                      # 1-D tensor, \n",
    "    relpaths = tf.decode_csv(filenames, [[\"\"],[\"\"],[\"\"],[\"\"]])  # a list of 1-D tensor, each element is a batch of prevs, or currs, or bkgs, or gts.\n",
    "    print type(relpaths), len(relpaths), relpaths[0].shape, relpaths[0].dtype\n",
    "#     return relpaths\n",
    "    \n",
    "    prev = get_pyramid(relpaths[0])\n",
    "    curr = get_pyramid(relpaths[1])\n",
    "    bkg  = get_pyramid(relpaths[2])\n",
    "    gt, mask = get_gt_and_mask(relpaths[3])\n",
    "    \n",
    "    scale0 = tf.concat([prev[0], curr[0], bkg[0]], axis=3)\n",
    "    scale1 = tf.concat([prev[1], curr[1], bkg[1]], axis=3)\n",
    "    scale2 = tf.concat([prev[2], curr[2], bkg[2]], axis=3)\n",
    "    \n",
    "    return scale0, scale1, scale2, gt, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse1(filenames):\n",
    "    \n",
    "    print type(filenames), filenames.shape                      # 1-D tensor, \n",
    "    relpaths = tf.decode_csv(filenames, [[\"\"],[\"\"],[\"\"],[\"\"]])  # a list of 1-D tensor, each element is a batch of prevs, or currs, or bkgs, or gts.\n",
    "    print type(relpaths), len(relpaths), relpaths[0].shape, relpaths[0].dtype\n",
    "#     return relpaths\n",
    "    \n",
    "    prev_paths = tf.reduce_join([rootpath1, relpaths[0]],axis=0)  #reduce_join, axis=0表示列方向，1-D tensor is viewed as 2-D tensor with row equaling 1\n",
    "    print type(prev_paths), prev_paths.shape, prev_paths.dtype\n",
    "#     return prev_paths\n",
    "\n",
    "    prev_imgs = [tf.cast(tf.image.rgb_to_grayscale(tf.image.decode_image(tf.read_file(prev_paths[i]))), dtype=tf.float32)  \\\n",
    "                 for i in range(prev_paths.shape.as_list()[0])]  #read_file, decode_img, rgb_to_grayscale, cast. grayscale is 3-D tensor with channels equaling 1\n",
    "    print type(prev_imgs), prev_imgs[0].shape, prev_imgs[0].dtype\n",
    "#     return prev_imgs\n",
    "\n",
    "    prev_imgs = tf.stack(prev_imgs, axis=0)\n",
    "    print prev_imgs.shape, prev_imgs.dtype\n",
    "#     return prev_imgs\n",
    "\n",
    "    prev_imgs_downscale1 = tf.nn.conv2d(prev_imgs, gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    print prev_imgs_downscale1.dtype, prev_imgs_downscale1.shape\n",
    "    prev_imgs_downscale1 = prev_imgs_downscale1[:,0::2,0::2,:]\n",
    "#     return prev_imgs_downscale1\n",
    "    \n",
    "    prev_imgs_downscale2 = tf.nn.conv2d(prev_imgs_downscale1, gaussian_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    print prev_imgs_downscale2.dtype, prev_imgs_downscale2.shape\n",
    "#     return prev_imgs_downscale2\n",
    "    prev_imgs_downscale2 = prev_imgs_downscale2[:,0::2,0::2,:]\n",
    "#     return prev_imgs_downscale2\n",
    "\n",
    "    gt_paths = tf.reduce_join([rootpath1, relpaths[3]], axis=0)    #1. 读取并解码，转换为2-Dtensor，转换为二值图, 转换为float类型\n",
    "#     return gt_paths\n",
    "    raw_gt_imgs = [tf.image.decode_image(tf.read_file(gt_paths[i])) for i in range(gt_paths.shape.as_list()[0])]\n",
    "    gt_imgs = [tf.cast((i >= 170), dtype=tf.float32) for i in raw_gt_imgs]\n",
    "    gt_imgs = tf.stack(gt_imgs, axis=0)\n",
    "#     return gt_imgs\n",
    "    \n",
    "    print raw_gt_imgs[0].shape, raw_gt_imgs[0].dtype\n",
    "    mask_imgs = [tf.cast(tf.not_equal(i, 85), dtype=tf.float32) for i in raw_gt_imgs]\n",
    "    mask_imgs = tf.stack(mask_imgs, axis=0)\n",
    "    return mask_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "rootpath1 = tf.stack([rootpath]*batch_size, axis=0)\n",
    "\n",
    "csv = tf.data.TextLineDataset(\"./bs/mybs/train.csv\")\n",
    "csv = csv.shuffle(buffer_size=1000)   # 先 shuffle 后 batch， 最后 parse\n",
    "csv = csv.batch(batch_size)\n",
    "\n",
    "csv = csv.map(_parse2)\n",
    "iterator_csv = csv.make_one_shot_iterator()\n",
    "one_element_csv = iterator_csv.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_element_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "#     a=sess.run(one_element_csv)\n",
    "#     a,b,c,d = sess.run(one_element_csv)\n",
    "    a,b,c,d,e = sess.run(one_element_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape, b.shape, c.shape, d.shape, e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype, b.dtype, c.dtype, d.dtype, e.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "cv2.imshow(\"a\",a[i, :,:, 0].astype(np.uint8))\n",
    "cv2.imshow(\"b\",a[i, :,:, 1].astype(np.uint8))\n",
    "# cv2.imshow(\"c\",a[1, :,:, 2].astype(np.uint8))\n",
    "cv2.imshow(\"gt\", d[i, :,:].astype(np.uint8)*255)\n",
    "cv2.imshow(\"mask\", e[i, :,:].astype(np.uint8)*255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(a[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape, a[0].dtype, a[1].shape, a[1].dtype, a[2].shape, a[2].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"a\", a[0][0,:,:,0].astype(np.uint8))\n",
    "cv2.imshow(\"b\", a[1][0,:,:,0].astype(np.uint8))\n",
    "cv2.imshow(\"c\", a[2][0,:,:,0].astype(np.uint8))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a[0].shape, a[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape, a[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"a\",a[0,:,:,0].astype(np.uint8))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(a[0][:,:,0].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a[1] == b[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"d\", d[:,:,0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"a\",a[:,:,::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(a[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    for i in range(21):\n",
    "        a,b,c,d = sess.run(one_element_csv)\n",
    "#         print a.shape, b.shape, c.shape, d.shape\n",
    "#         print a.dtype, b.dtype, c.dtype, d.dtype\n",
    "        aes.append(a)\n",
    "        bes.append(b)\n",
    "        ces.append(c)\n",
    "        des.append(d)\n",
    "        \n",
    "#         skimage.io.imshow(a)\n",
    "#         skimage.io.imshow(b)\n",
    "#         skimage.io.imshow(c)\n",
    "#         skimage.io.imshow(np.concatenate([d,d,d], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aes[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(des[9][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as s:\n",
    "    c = s.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv = open(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tf.read_file(\"./juri1.jpg\")\n",
    "b = tf.image.decode_image(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as s:\n",
    "    c = s.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"c\", c[:,:,::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about default_graph\n",
    "print tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#about total_variation\n",
    "x = tf.constant([[[[1],[2],[3]],[[6],[5],[4]],[[8],[7],[9]]], [[[1],[2],[3]],[[6],[5],[4]],[[8],[7],[8]]]])\n",
    "x_var = tf.image.total_variation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3), Dimension(3), Dimension(1)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[1],\n",
       "          [2],\n",
       "          [3]],\n",
       " \n",
       "         [[6],\n",
       "          [5],\n",
       "          [4]],\n",
       " \n",
       "         [[8],\n",
       "          [7],\n",
       "          [9]]],\n",
       " \n",
       " \n",
       "        [[[1],\n",
       "          [2],\n",
       "          [3]],\n",
       " \n",
       "         [[6],\n",
       "          [5],\n",
       "          [4]],\n",
       " \n",
       "         [[8],\n",
       "          [7],\n",
       "          [8]]]], dtype=int32), array([25, 23], dtype=int32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.run([x,x_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npx = np.array([[[1],[2],[3]],[[6],[5],[4]],[[8],[7],[9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npx[1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gx = npx[1:,:,:] - npx[:-1,:,:]\n",
    "gy = npx[:,1:,:] - npx[:,:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(gx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(gy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(gx).sum() + np.abs(gy).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.int32, shape=[None, 3, 3])\n",
    "x_var = tf.image.total_variation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about resize_images\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[2,3,4,1])\n",
    "resize_x = tf.image.resize_images(x, size=[6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Tensor([3,4], dtype=tf.float32, value_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(tf.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about shape\n",
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
    "t_shp = tf.shape(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(t_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about conv2d_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.Session(config=config) as s:\n",
    "        scale0 = tf.placeholder(dtype=tf.float32, shape=[None, 60, 80, 512])\n",
    "        scale1 = tf.placeholder(dtype=tf.float32, shape=[None, 30, 40, 512])\n",
    "        w = tf.get_variable(\"w\", shape=[3,3,512,512], dtype=tf.float32, initializer=tf.random_normal_initializer())\n",
    "        init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deconv1 = tf.nn.conv2d_transpose(scale1, w, output_shape=tf.shape(scale0), strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = s.run(deconv1, feed_dict={scale1:np.random.rand(2,30,40,512), scale0:np.random.rand(2,60,80,512)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deconv_reshp = tf.reshape(deconv, shape=[-1]+y.shape.as_list()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_reshp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch_size = tf.shape(y)[0]\n",
    "deconv1_shape = tf.stack([a[0], a[1], a[2], a[3]])\n",
    "deconv1 = tf.nn.conv2d_transpose(x, w, output_shape=deconv1_shape, strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import slim\n",
    "\n",
    "inputs = tf.random_normal(shape=[3, 97, 97, 10])\n",
    "\n",
    "conv1 = slim.conv2d(inputs, num_outputs=20, kernel_size=3, stride=4)\n",
    "\n",
    "de_weight = tf.get_variable('de_weight', shape=[3, 3, 10, 20])\n",
    "\n",
    "deconv1 = tf.nn.conv2d_transpose(conv1, filter=de_weight, output_shape=tf.shape(inputs),\n",
    "                                 strides=[1, 3, 3, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npx = np.random.randint(10, size=(2,8,8,3)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "s.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_deconv = s.run(deconv, feed_dict={x:npx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_deconv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about reshape\n",
    "x = tf.placeholder(dtype=tf.int32, shape=[None, 3, 4, 4, 3])\n",
    "x_reshp = tf.reshape(x, shape=[-1, 4, 4, 3])\n",
    "x_reshp_reshp = tf.reshape(x_reshp, shape=[-1, 3, 4, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(range(2*3*4*4*3)).reshape((2,3,4,4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfa, tfa_reshp, tfa_reshp_reshp = s.run([x,x_reshp,x_reshp_reshp], feed_dict={x: a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfa_reshp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tfa_reshp_reshp == tfa).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about dynamic rnn\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 4, 10])\n",
    "x_splt = tf.unstack(x, axis=1)\n",
    "rnn_cell = tf.nn.rnn_cell.BasicRNNCell(3)\n",
    "# init_state = tf.zeros_like(x, dtype=tf.float32)\n",
    "# init_state = tf.zeros(dtype=tf.float32, shape=[None, rnn_cell.state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x.shape[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.shape[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell.zero_state(3, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_splt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.dynamic_rnn(rnn_cell, x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about pair wise l2 dist\n",
    "npa = np.array([[1,2],[3,4]])\n",
    "npb = np.array([[5,6],[7,8], [9, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = a.dot(b.T)\n",
    "te = np.square(a).sum(axis=1)\n",
    "tr = np.square(b).sum(axis=1)\n",
    "print M.shape, te.shape, tr.shape, np.matrix(te).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = -2 * M + tr + np.matrix(te).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "b = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "ra = tf.reshape(tf.reduce_sum(tf.square(a), axis=1), shape=[-1,1])\n",
    "rb = tf.reshape(tf.reduce_sum(tf.square(b), axis=1), shape=[-1,1])\n",
    "dist_mat = ra + tf.transpose(rb) - 2 * tf.matmul(a, tf.transpose(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.run(dist_mat, feed_dict={a:npa, b:npb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "initial_learning_rate = 0.1 #初始学习率\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate,\n",
    "                                           global_step=global_step,\n",
    "                                           decay_steps=10,decay_rate=0.9)\n",
    "# opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "add_global = global_step.assign_add(1)\n",
    "s.run(tf.global_variables_initializer())\n",
    "print(s.run(learning_rate))\n",
    "for i in range(10):\n",
    "    add_g, rate = s.run([add_global, learning_rate])\n",
    "    print add_g, rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 * pow(0.9, 9/10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about concat\n",
    "x1 = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 4])\n",
    "x2 = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 5])\n",
    "c = tf.concat([x1, x2], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about conv gru\n",
    "\n",
    "class ConvGRUCell(tf.nn.rnn_cell.RNNCell):\n",
    "    \"\"\"\n",
    "    Note that:\n",
    "    1. number of channels of update gate, reset gate, hidden state and new state must be equal\n",
    "    2. height and width of hidden state, input and new state must be equal\n",
    "    \"\"\"\n",
    "    def __init__(self, ix_channels, ih_channels, kernel_shape):\n",
    "        self._ix_channels = ix_channels\n",
    "        self._ih_channels = ih_channels\n",
    "        self._kernel_shape = kernel_shape\n",
    "        \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        scope = scope or type(self).__name__\n",
    "        with tf.variable_scope(scope):\n",
    "            in_channels = self._ix_channels + self._ih_channels\n",
    "            shape_length = len(inputs.shape.as_list())\n",
    "            print \"shape_length\", shape_length\n",
    "\n",
    "            W_ur = tf.get_variable(\"W_ur\", shape=self._kernel_shape+[in_channels, 2*self._ih_channels], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            W_h  = tf.get_variable(\"W_h\",  shape=self._kernel_shape+[in_channels,   self._ih_channels], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            \n",
    "            b_ur = tf.get_variable(\"b_ur\", shape=[2*self._ih_channels], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            b_h  = tf.get_variable(\"b_h\",  shape=[  self._ih_channels], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "            \n",
    "            ur = tf.nn.sigmoid(tf.nn.conv2d(tf.concat(values=[inputs, state], axis=shape_length-1),\n",
    "                                            W_ur, strides=[1,1,1,1], padding=\"SAME\") + b_ur)\n",
    "            print \"ur.shape\", ur.shape\n",
    "            u, r = tf.split(ur, num_or_size_splits=2, axis=shape_length-1)\n",
    "            print \"u and r's shape\", u.shape, r.shape\n",
    "            \n",
    "            r_state = r * state\n",
    "            print \"r_state.shape\", r_state.shape\n",
    "            c = tf.tanh(tf.nn.conv2d(tf.concat(values=[inputs, r_state], axis=shape_length-1),\n",
    "                                     W_h, strides=[1,1,1,1], padding=\"SAME\") + b_h)\n",
    "            print \"c.shape\", c.shape\n",
    "            new_state = u * state + (1-u) * c\n",
    "            print \"new_state\", new_state.shape\n",
    "        self.wur, self.wh, self.bur, self.bh, self.u, self.r, self.r_state, self.c = W_ur, W_h, b_ur, b_h, u, r, r_state, c\n",
    "        return new_state, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 5, 5, 3])\n",
    "init_state = tf.placeholder(dtype=tf.float32, shape=[None, 5, 5, 4])\n",
    "cell = ConvGRU(3, 4, [3,3])\n",
    "tfo, tfns = cell(x, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.wur.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert cell.wur.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"ConvGRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npx = np.random.randint(10, size=(2,5,5,3))\n",
    "nph = np.random.randint(10, size=(2,5,5,4))\n",
    "feed_dict={x: npx, init_state: nph}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = tf.Session(graph=cell.wur.graph)\n",
    "init_op = tf.global_variables_initializer()\n",
    "s.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npo, npns, wur, wh, bur, bh, u, r, r_state, c = s.run([tfo, tfns, cell.wur, cell.wh, cell.bur, cell.bh, cell.u, cell.r, cell.r_state, cell.c], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import np_conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([npx, nph], axis=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ur = 1.0/ (1+np.exp(-1*(np_conv2d.conv2d(np.concatenate([npx, nph], axis=3), wur) + bur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npu = ur[:,:,:,:4]\n",
    "npr = ur[:,:,:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(npu, u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(npr, r).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(r*nph, r_state).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npc = np.tanh(np_conv2d.conv2d(np.concatenate([npx, r_state],axis=3), wh) + bh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(npc, c).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about conv rnn\n",
    "class Conv_RNNCell(tf.nn.rnn_cell.RNNCell):\n",
    "    def __init__(self, ix_channels, ih_channels, o_channels, wx_size, wh_size):\n",
    "        self.ix_channels = ix_channels\n",
    "        self.ih_channels = ih_channels\n",
    "        self.o_channels = o_channels\n",
    "        \n",
    "        assert wx_size == wh_size\n",
    "        self.wx_size = wx_size\n",
    "        self.wh_size = wh_size\n",
    "    \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        scope = scope or type(self).__name__\n",
    "        with tf.variable_scope(scope):\n",
    "            W_x = tf.get_variable(\"W_x\", shape=[self.wx_size, self.wx_size, self.ix_channels, self.o_channels], \n",
    "                                  dtype=tf.float32, initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1e-3))\n",
    "            W_h = tf.get_variable(\"W_h\", shape=[self.wh_size, self.wh_size, self.ih_channels, self.o_channels], \n",
    "                                  dtype=tf.float32, initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1e-3))\n",
    "            b = tf.get_variable(\"b\", shape=[self.o_channels], \n",
    "                                  dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            w_conv_x = tf.nn.conv2d(inputs, W_x, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            w_conv_h = tf.nn.conv2d(state,  W_h, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            new_state = tf.nn.tanh(w_conv_x + w_conv_h + b)\n",
    "            \n",
    "            self.wx = W_x\n",
    "            self.wh = W_h\n",
    "            self.b  = b\n",
    "        output = new_state\n",
    "        return output, new_state        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 5, 5, 1])\n",
    "init_state = tf.placeholder(dtype=tf.float32, shape=[None, 5, 5, 2])\n",
    "conv_rnn_cell = Conv_RNNCell(1, 2, 3, 5, 5)\n",
    "output, new_state = conv_rnn_cell(x, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"Conv_RNNCell\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.graph is init_state.graph\n",
    "assert x.graph is output.graph\n",
    "assert x.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npx = np.random.randint(10, size=(2,5,5,1))\n",
    "nph = np.random.randint(10, size=(2,5,5,2))\n",
    "feed_dict={x: npx, init_state: nph}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op1 = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.run(init_op1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npo, npns, wx, wh, b = s.run([output, new_state, conv_rnn_cell.wx, conv_rnn_cell.wh, conv_rnn_cell.b], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import np_conv2d\n",
    "reload(np_conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = np_conv2d.conv2d(npx, wx)\n",
    "e = np_conv2d.conv2d(nph, wh)\n",
    "c = np.tanh(d + e + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.isclose(c, npo).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about rnn_cell\n",
    "class RNNCell(tf.nn.rnn_cell.RNNCell):\n",
    "    def __init__(self, input_size, state_size):\n",
    "        self.input_size = input_size\n",
    "        self._state_size = state_size\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._state_size\n",
    "        \n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        scope = scope or type(self).__name__\n",
    "        with tf.variable_scope(scope):\n",
    "            W_x = tf.get_variable('W_x', shape=[self.input_size, self._state_size], dtype=tf.float32, \n",
    "                                initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1e-3))\n",
    "            W_h = tf.get_variable('W_h', shape=[self._state_size, self._state_size], dtype=tf.float32,\n",
    "                                 initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1e-3))\n",
    "            b = tf.get_variable('b', shape=[self._state_size], dtype=tf.float32, \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "            new_state = tf.nn.tanh(tf.matmul(inputs, W_x) + tf.matmul(state, W_h) + b)\n",
    "            print W_x.name, W_h.name\n",
    "        output = new_state\n",
    "        self.wx, self.wh, self.b = (W_x, W_h, b)\n",
    "        return output, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn = RNNCell(3,2)\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 3])\n",
    "state = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "output, new_state = rnn(x, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npx = np.array([[1,2,3]])\n",
    "nph = np.array([[4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "s.run(init_op)\n",
    "npo, npns, wx, wh, b = s.run([output, new_state, rnn.wx, rnn.wh, rnn.b], feed_dict={x:npx, state:nph})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print npo, npns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tanh(npx.dot(wx) + nph.dot(wh) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.BasicRNNCell(2)\n",
    "x1 = tf.placeholder(dtype=tf.float32, shape=[None, 3])\n",
    "state1 = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "output1, new_state1 = cell(x1, state1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run([output1, new_state1, cell.weights], feed_dict={x1:npx, state1:nph})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tanh(np.concatenate([npx, nph], axis=1).dot(np.array([[-0.60721934,  0.52676451],\n",
    "         [-0.20876437, -0.06029028],\n",
    "         [-0.13075608, -0.82820529],\n",
    "         [ 0.18204689, -0.1674763 ],\n",
    "         [-0.03953016, -0.1331923 ]], dtype=np.float32)) + np.array([0.,0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about max_pool\n",
    "a = tf.placeholder(dtype=tf.float32, shape=[1,3,3,1])\n",
    "b = tf.nn.max_pool(a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npa = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about split\n",
    "a = tf.placeholder(dtype=tf.float32, shape=[None, 128, 48, 3])\n",
    "b,c,d,e = tf.split(a, num_or_size_splits=[32,32,32,32], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print b.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = np.array([1,2,3,4,5,6,7,8,9,0]).reshape(5, 2)\n",
    "npb, npc = s.run([b,c], feed_dict={a:npa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about conv\n",
    "a = tf.placeholder(dtype=tf.float32, shape=[None,7,7,512])\n",
    "w = tf.placeholder(dtype=tf.float32, shape=[7,7,512,4096])\n",
    "b = tf.nn.conv2d(a, w, strides=[1, 7, 7, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = np.array([1,1,1,0,0,1,1,1,0,0,1,1,0,0,1,1]).reshape(1,4,4,1)\n",
    "npw = np.array([-1,1,-1,1,1,1,1,-1,-1, 1,-1,1,-1,1,1,-1,-1,-1]).reshape(3,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print npa.shape, npw.shape\n",
    "print npa[0,:,:,0]\n",
    "print npw[:,:,0,0]\n",
    "print npw[:,:,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npb = s.run(b, feed_dict={a:npa, w:npw})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npb[0,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about pow\n",
    "a = tf.placeholder(dtype=tf.float32, shape=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(tf.pow(a,2), feed_dict={a:np.array([1,2])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about norm\n",
    "# norm(a, 2), 表示的是l2-norm，就是所有元素的平方和，再开方\n",
    "a = tf.placeholder(dtype=tf.float32, shape=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(tf.norm(a,2), feed_dict={a:np.array([[3,4]])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about equal\n",
    "a = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "b = tf.placeholder(dtype=tf.int32, shape=[a.shape[0]])\n",
    "c = tf.placeholder(dtype=tf.int32, shape=a.get_shape())\n",
    "print a.shape, b.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = 1 - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(d, feed_dict={a: np.array([0,1,2,3,3])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = tf.subtract(1, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about substract\n",
    "a = tf.placeholder(dtype=tf.float32, shape=[3,2])\n",
    "b = 1-a\n",
    "d = tf.subtract(1., a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([[1,2],[3,4],[5,6]])\n",
    "s.run([b,d],feed_dict={a : c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about boolean_mask\n",
    "w = tf.placeholder(dtype=tf.float32, shape=[None,5])\n",
    "mask = tf.placeholder(dtype=tf.bool, shape=[None, 5])\n",
    "w_mask = tf.boolean_mask(w, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print w.shape, mask.shape, w_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.random.random((10, 5))\n",
    "m = np.eye(10, 5)#.astype(bool)\n",
    "s.run(w_mask, feed_dict={w : a, mask : m})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# about name_score variable_scope get_variable Variable\n",
    "with tf.variable_scope(\"foo\", reuse=True):\n",
    "    v = tf.get_variable(\"v\", [1])  # v.name == \"foo/v:0\"\n",
    "    w = tf.get_variable(\"w\", [1])  # w.name == \"foo/w:0\"\n",
    "    u = tf.Variable(initial_value=[1], name=\"u\")\n",
    "    print tf.get_variable_scope().name, v.name, w.name, u.name\n",
    "with tf.variable_scope(\"foo\", reuse=True):\n",
    "    v1 = tf.get_variable(\"v\")  # The same as v above.\n",
    "    w1 = tf.get_variable(\"w\")\n",
    "    \n",
    "    print tf.get_variable_scope().name, v1.name, w1.name, u.name\n",
    "print v1 is v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('name_scope_x'):\n",
    "    var1 = tf.get_variable(name='var1', shape=[1], dtype=tf.float32)\n",
    "    var3 = tf.Variable(name='var2', initial_value=[2], dtype=tf.float32)\n",
    "    var4 = tf.Variable(name='var2', initial_value=[2], dtype=tf.float32)\n",
    "#     var3 = tf.get_variable(name='var1')\n",
    "print var1.name, var3.name, var4.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- variable_scope 对get_variable 和 Variable都有效\n",
    "- name_scope 只对 Variable 有效\n",
    "- 如果get_variable所在的scope的reuse为True，则表示重复使用变量，提供给get_variable的变量名必须是之前声明过的\n",
    "- 如果get_variable所在的scope的reuse为False，则表示不重复使用变量，提供给get_variable的变量名必须是之前没有声明过的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"fuck\"):\n",
    "    v = tf.Variable(initial_value=[1], name='v')\n",
    "    p = tf.placeholder(tf.float32)\n",
    "with tf.variable_scope(\"fuck\"):\n",
    "    v = tf.Variable(initial_value=[2], name='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    assert foo_scope.name == \"foo\"\n",
    "with tf.variable_scope(\"bar\"):\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        assert other_scope.name == \"bar/baz\"\n",
    "        with tf.variable_scope(foo_scope) as foo_scope2:\n",
    "            assert foo_scope2.name == \"foo\"  # Not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about softmax\n",
    "logits = tf.constant([.1,.3,.5,.9], dtype=tf.float32)\n",
    "t = tf.nn.softmax(logits)\n",
    "\n",
    "onehot_labels = tf.constant([0,0,0,1], dtype=tf.float32)\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels=onehot_labels, logits=logits)\n",
    "\n",
    "loss_entropy = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print s.run(t)\n",
    "print s.run(entropy)\n",
    "print s.run(loss_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about l2_loss\n",
    "a = tf.constant([1,2,3,4], dtype=tf.float32)\n",
    "l2_a = tf.nn.l2_loss(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(l2_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# about assign\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "W = tf.assign(W, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print sess.run([W, W.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about ExponentialMovingAverage\n",
    "v1 = tf.Variable(0, dtype=tf.float32)\n",
    "step = tf.Variable(0, trainable=False)\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "mainain_averages_op = ema.apply([v1])  #将 v1 添加进滑动平均的列表\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "    \n",
    "    sess.run(tf.assign(v1, 5))\n",
    "    print sess.run([v1, ema.average(v1)]) #ema.average 获取shadow_variable，\n",
    "    sess.run(mainain_averages_op)         #这一步是更新shadow_variable \n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# about embedding_lookup\n",
    "train_inputs = tf.placeholder(tf.int32, shape=[2,2])\n",
    "embeddings = tf.Variable(tf.random_uniform([100, 10], -1.0, 1.0))\n",
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(embed, feed_dict={train_inputs : [[1,2],[2,3]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "fetch = s.run([x, wx_b], feed_dict={x : np.random.random((100, 64))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
